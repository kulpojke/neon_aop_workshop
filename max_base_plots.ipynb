{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio \n",
    "import gdal\n",
    "import math\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round1000(x):\n",
    "    ''' \n",
    "    round1000(x):\n",
    "    Rounds value to nearest 1000\n",
    "    '''\n",
    "    return(1000 * math.floor(x / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def is_on_boundary(x, y):\n",
    "    '''\n",
    "    Returns: \n",
    "    0 if false,\n",
    "    'hor' if on horizaontal boundary,\n",
    "    'ver' if on verticle boudry\n",
    "    '''\n",
    "    answer = 0\n",
    "    r = 20\n",
    "    extent  = [x - r , x + r , y - r , y + r ]\n",
    "    names   = ['xMin', 'xMax', 'yMin', 'yMax']\n",
    "    extent = dict(zip(names, extent)) \n",
    "\n",
    "    # get tile coords\n",
    "    tile_east =  round1000(x)\n",
    "    tile_north =  round1000(y)\n",
    "\n",
    "    answer = (f'{tile_east}_{tile_north}')\n",
    "    \n",
    "    # If the plot is on a horizontal tile boundary,\n",
    "    # that boundary falls between yMax and yMin\n",
    "    bound_below = round1000(extent['yMax'])\n",
    "    if  bound_below >= extent['yMin']:\n",
    "        answer = 'hor'\n",
    "\n",
    "    # If the plot is on a vertical tile boundary,\n",
    "    # that boundary falls between xMax and xMin\n",
    "    bound_left = round1000(extent['xMax'])\n",
    "    if  bound_left >= extent['xMin']:\n",
    "        answer = 'ver'\n",
    "        \n",
    "    return(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_coords(plot_spdf):\n",
    "    '''\n",
    "    Takes base column array of plot entries, calculates coordinates\n",
    "    of tiles and returns them as a column vector of strings\n",
    "    '''\n",
    "    x = plot_spdf['easting']\n",
    "    y = plot_spdf['northing']\n",
    "    boundary = is_on_boundary(x, y)\n",
    "    return(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_plots_shp(data_path='/home/jovyan/data/all_plots/'):\n",
    "    '''\n",
    "    Downloads the NEON TOS plots data\n",
    "    \n",
    "    --------\n",
    "    Parameters\n",
    "    --------\n",
    "    data_path path to which data will be downloaded\n",
    "    '''\n",
    "    # make data directory exists \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "    handle = requests.get(url='https://data.neonscience.org/api/v0/documents/All_NEON_TOS_Plots_V8')\n",
    "    \n",
    "    with open(data_path + 'All_NEON_TOS_Plots_V8.zip', 'wb') as f:\n",
    "        f.write(handle.content)\n",
    "    \n",
    "    with zipfile.ZipFile(data_path + 'All_NEON_TOS_Plots_V8.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path)\n",
    "\n",
    "    NEON_all_plots = gpd.read_file(f'{data_path}All_NEON_TOS_Plots_V8/All_NEON_TOS_Plot_Polygons_V8.shp')\n",
    "    \n",
    "    return(NEON_all_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEON_all_plots = download_plots_shp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_plots_shp()\n",
    "sitecodes = ['BART', 'TEAK', 'HARV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_sites_of_interest(sitecodes, cull_boundary_plots=True):\n",
    "    for sitecode in sitecodes:\n",
    "        # find all base plots for the sitecode\n",
    "        base_plots_SPDF = NEON_all_plots.loc[(NEON_all_plots.siteID == sitecode) & (NEON_all_plots.subtype == 'basePlot')]\n",
    "        # make a dataframe of plot coordinates\n",
    "        coord_df =  pd.DataFrame()\n",
    "        coord_df['plotID'] = base_plots_SPDF.plotID\n",
    "        coord_df['coord_String'] = get_plot_coords(base_plots_SPDF)\n",
    "        # Remove plots that cross a mosaic tile boundary.\n",
    "        # Maybe not necessary if we are using EPTs\n",
    "        # and cloud based tiled tifs?\n",
    "        if cull_boundary_plots:\n",
    "            coord_df = coord_df.loc[(coord_df.coord_String != 'hor') & (coord_df.coord_String != 'ver')]\n",
    "        # count how many plots are in each mosaic tile\n",
    "        coord_count = coord_df.groupby('coord_String').count()\n",
    "        coord_count = list(coord_count.index)\n",
    "        return(coord_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_count = define_sites_of_interest(sitecodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cyverse_iput(files_dict, iput_path, username):\n",
    "    '''\n",
    "    Downloads and saves data to iROD server using cyverse\n",
    "    using icomands.  A connection must be established using\n",
    "    iinit before this can be used. For more info see:\n",
    "    https://cyverse-2020-neon-aop-workshop.readthedocs-hosted.com/en/latest/step4.html\n",
    "\n",
    "    --------\n",
    "    Parameters\n",
    "    --------\n",
    "    files_dict - a dictionary with file names as keys and api urls as values\n",
    "    iput_path  - path on the server where files are to be stored\n",
    "    username   - cyverse userneame    \n",
    "    '''\n",
    "    for fname, url in files_dict.items():\n",
    "        # make sure target directory exists on server\n",
    "        \n",
    "        \n",
    "        \n",
    "        # download \n",
    "        response = requests.get(url)\n",
    "        with open(f'data/{fname}', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        # copy to server\n",
    "        cmd = f'iput -KPf {fname} /iplant/home/{username}/data/{fname}'\n",
    "        answer = subprocess.call(cmd, shell=True)\n",
    "        # verify transfer\n",
    "        if 'ERROR' in answer:\n",
    "            print(answer)\n",
    "        \n",
    "        # remove local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_local(files_dict, savedir, username=None):\n",
    "    '''\n",
    "    saves files into savedir.\n",
    "    username only exists to make the signature match\n",
    "    that of download_cyverse_iput\n",
    "    '''\n",
    "    savedir.rstrip('/')\n",
    "    for fname, url in files_dict.items():\n",
    "        # make sure target directory exists \n",
    "        os.makedirs(savedir, exist_ok=True)       \n",
    "        # download \n",
    "        response = requests.get(url)\n",
    "        with open(f'{savedir}/{fname}', 'wb') as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AOP_from_API(coord_count, sitecodes, productcodes, daterange = 'most recent', download_func=download_local, username=None, savedir='data'):\n",
    "    '''\n",
    "    Downloads files from the NEON AOP API.\n",
    "    \n",
    "    --------\n",
    "    Parameters\n",
    "    --------\n",
    "    coord_count   - list of local UTM coordinates, as strings,  seperated by '_', \n",
    "                    like the output of define_sites_of_interest()\n",
    "    \n",
    "    sitecodes     - list of NEON sitecodes, e.g. ['BART', 'TEAK']\n",
    "    \n",
    "    productcodes  - list of NEON AOP product codes, e.g.\n",
    "                    ['DP3.30006.001', 'DP3.30006.001'].\n",
    "                    If codes are not for AOP products errors will result.\n",
    "                    There is no exception handling built in for this case.\n",
    "    \n",
    "    daterange     - list of yyyy-mm dates for each desired month, e.g.\n",
    "                    ['2019-08', '2019-09', '2019-10'], or 'most recent'\n",
    "                    for most recent available month.\n",
    "                   \n",
    "    download_func - function specifying where the data should be saved.\n",
    "                    Some functions are provided in this library (download_local \n",
    "                    and download_cyverse_iput)User defined functions must fit \n",
    "                    the signature func(files_dict, savedir, username), where:\n",
    "                        - files_dict is a dictionary of the form \n",
    "                          {'filename' : 'download_url'}\n",
    "                        - savedir specifies the directory where files will be saved \n",
    "                          (specified by the keyword argument 'savedir' (see below).)\n",
    "                        - username if needed is is a username to access remote storage,\n",
    "                          if not needed  is None. (this argument is need for \n",
    "                          download_cyverse_iput)\n",
    "                    If not specified, defaults to download_local, see docstring of\n",
    "                    download_local and download_cyverse_iput for more information.\n",
    "    \n",
    "    username      - Username for remote storage if needed. Defaults to None.\n",
    "\n",
    "    savedir       - Path to directory where downloads will be saved.  \n",
    "    '''    \n",
    "    server = 'https://data.neonscience.org/api/v0/'\n",
    "    for site in sitecodes:\n",
    "        for product in productcodes:\n",
    "            url = f'{server}sites/{site}'\n",
    "            response = requests.get(url)\n",
    "            data = response.json()['data']\n",
    "            dates = data['dataProducts'][0]['availableMonths']\n",
    "            if daterange == 'most recent':\n",
    "                # get the most recent date\n",
    "                dates = [max(dates)]\n",
    "            else:\n",
    "                try:\n",
    "                    # get dates in the range\n",
    "                    assert isinstance(daterange,list)\n",
    "                    begin, terminate = min(daterange), max(daterange)\n",
    "                    dates = [d  for d in dates if (d >= begin) and (d <= terminate)]                 \n",
    "                except AssertionError:\n",
    "                    print('daterange must be a list, e.g. [\\'2020-10\\', \\'2019-10\\']')\n",
    "                    return(None)\n",
    "            # determine the existing products for the dates \n",
    "            for date in dates:\n",
    "                url = f'{server}data/{product}/{site}/{date}'\n",
    "                response = requests.get(url)\n",
    "                data = response.json()\n",
    "                fnames = data['data']['files']\n",
    "                files_dict = dict()\n",
    "                for f in fnames:\n",
    "                    for coord in coord_count:\n",
    "                        if coord in f['name']:\n",
    "                            files_dict[f['name']] = f['url']\n",
    "            # download the files\n",
    "            try:\n",
    "                download_func(files_dict, savedir, username)\n",
    "            except Exception as e:\n",
    "                print(f'This happened:\\n\\n{e}')\n",
    "        print(f'Done downloading files to {savedir}')     \n",
    "    return(files_dict, sitecodes)\n",
    "                \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done downloading files to data\n"
     ]
    }
   ],
   "source": [
    "files_dict, sitecodes = get_AOP_from_API(coord_count, ['BART'],productcodes=['DP3.30006.001'] ,daterange=['2019-08', '2019-08'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tile_csv(files_dict, sitecodes, savedir='data'):\n",
    "    part = '_'.join(sitecodes)\n",
    "    filename = f'tile_list_{part}.tsv'\n",
    "    with open(filename, 'w') as f:\n",
    "        for key in files_dict.keys(): \n",
    "            base = key.rpartition('_')[0]\n",
    "            f.write(f'{base}\\n')\n",
    "    return(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = make_tile_csv(files_dict, sitecodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tile_list_BART_TEAK_HARV.tsv'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
