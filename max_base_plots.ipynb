{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio \n",
    "import gdal\n",
    "import math\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round1000(x):\n",
    "    ''' \n",
    "    round1000(x):\n",
    "    Rounds value to nearest 1000\n",
    "    '''\n",
    "    return(1000 * math.floor(x / 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def is_on_boundary(x, y):\n",
    "    '''\n",
    "    Returns: \n",
    "    0 if false,\n",
    "    'hor' if on horizaontal boundary,\n",
    "    'ver' if on verticle boudry\n",
    "    '''\n",
    "    answer = 0\n",
    "    r = 20\n",
    "    extent  = [x - r , x + r , y - r , y + r ]\n",
    "    names   = ['xMin', 'xMax', 'yMin', 'yMax']\n",
    "    extent = dict(zip(names, extent)) \n",
    "\n",
    "    # get tile coords\n",
    "    tile_east =  round1000(x)\n",
    "    tile_north =  round1000(y)\n",
    "\n",
    "    answer = (f'{tile_east}_{tile_north}')\n",
    "    \n",
    "    # If the plot is on a horizontal tile boundary,\n",
    "    # that boundary falls between yMax and yMin\n",
    "    bound_below = round1000(extent['yMax'])\n",
    "    if  bound_below >= extent['yMin']:\n",
    "        answer = 'hor'\n",
    "\n",
    "    # If the plot is on a vertical tile boundary,\n",
    "    # that boundary falls between xMax and xMin\n",
    "    bound_left = round1000(extent['xMax'])\n",
    "    if  bound_left >= extent['xMin']:\n",
    "        answer = 'ver'\n",
    "        \n",
    "    return(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_coords(plot_spdf):\n",
    "    '''\n",
    "    Takes base column array of plot entries, calculates coordinates\n",
    "    of tiles and returns them as a column vector of strings\n",
    "    '''\n",
    "    x = plot_spdf['easting']\n",
    "    y = plot_spdf['northing']\n",
    "    boundary = is_on_boundary(x, y)\n",
    "    return(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_plots_shp(data_path='/home/jovyan/data/all_plots/'):\n",
    "    '''\n",
    "    Downloads the NEON TOS plots data\n",
    "    \n",
    "    --------\n",
    "    Parameters\n",
    "    --------\n",
    "    data_path path to which data will be downloaded\n",
    "    '''\n",
    "    # make data directory exists \n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "    handle = requests.get(url='https://data.neonscience.org/api/v0/documents/All_NEON_TOS_Plots_V8')\n",
    "    \n",
    "    with open(data_path + 'All_NEON_TOS_Plots_V8.zip', 'wb') as f:\n",
    "        f.write(handle.content)\n",
    "    \n",
    "    with zipfile.ZipFile(data_path + 'All_NEON_TOS_Plots_V8.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path)\n",
    "\n",
    "    NEON_all_plots = gpd.read_file(f'{data_path}All_NEON_TOS_Plots_V8/All_NEON_TOS_Plot_Polygons_V8.shp')\n",
    "    \n",
    "    return(NEON_all_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEON_all_plots = download_plots_shp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_plots_shp()\n",
    "sitecodes = ['BART', 'TEAK', 'HARV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_sites_of_interest(sitecodes, cull_boundary_plots=True):\n",
    "    for sitecode in sitecodes:\n",
    "        # find all base plots for the sitecode\n",
    "        base_plots_SPDF = NEON_all_plots.loc[(NEON_all_plots.siteID == sitecode) & (NEON_all_plots.subtype == 'basePlot')]\n",
    "        # make a dataframe of plot coordinates\n",
    "        coord_df =  pd.DataFrame()\n",
    "        coord_df['plotID'] = base_plots_SPDF.plotID\n",
    "        coord_df['coord_String'] = get_plot_coords(base_plots_SPDF)\n",
    "        # Remove plots that cross a mosaic tile boundary.\n",
    "        # Maybe not necessary if we are using EPTs\n",
    "        # and cloud based tiled tifs?\n",
    "        if cull_boundary_plots:\n",
    "            coord_df = coord_df.loc[(coord_df.coord_String != 'hor') & (coord_df.coord_String != 'ver')]\n",
    "        # count how many plots are in each mosaic tile\n",
    "        coord_count = coord_df.groupby('coord_String').count()\n",
    "        coord_count = list(coord_count.index)\n",
    "        return(coord_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_count = define_sites_of_interest(sitecodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cyverse_iput(files_dict, iput_path, username):\n",
    "    '''\n",
    "    Downloads and saves data to iROD server using cyverse\n",
    "    using icomands.  A connection must be established using\n",
    "    iinit before this can be used. For more info see:\n",
    "    https://cyverse-2020-neon-aop-workshop.readthedocs-hosted.com/en/latest/step4.html\n",
    "\n",
    "    --------\n",
    "    Parameters\n",
    "    --------\n",
    "    files_dict - a dictionary with file names as keys and api urls as values\n",
    "    iput_path  - path on the server where files are to be stored\n",
    "    username   - cyverse userneame    \n",
    "    '''\n",
    "    for fname, url in files_dict.items():\n",
    "        # make sure target directory exists on server\n",
    "        \n",
    "        \n",
    "        \n",
    "        # download \n",
    "        response = requests.get(url)\n",
    "        with open(f'data/{fname}', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        # copy to server\n",
    "        cmd = f'iput -KPf {fname} /iplant/home/{username}/data/{fname}'\n",
    "        answer = subprocess.call(cmd, shell=True)\n",
    "        # verify transfer\n",
    "        if 'ERROR' in answer:\n",
    "            print(answer)\n",
    "        \n",
    "        # remove local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_local(files_dict, savedir, username=None):\n",
    "    '''\n",
    "    saves files into savedir.\n",
    "    username only exists to make the signature match\n",
    "    that of download_cyverse_iput\n",
    "    '''\n",
    "    savedir.rstrip('/')\n",
    "    for fname, url in files_dict.items():\n",
    "        # make sure target directory exists on server\n",
    "        os.makedirs(savedir, exist_ok=True)       \n",
    "        # download \n",
    "        response = requests.get(url)\n",
    "        with open(f'{savedir}/{fname}', 'wb') as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_API(coord_count, sitecodes, productcodes=['DP1.30003.001'], daterange = 'most recent', download_func=download_local, username=None, savedir='data'):\n",
    "    server = 'https://data.neonscience.org/api/v0/'\n",
    "    for site in sitecodes:\n",
    "        for product in productcodes:\n",
    "            url = f'{server}sites/{site}'\n",
    "            response = requests.get(url)\n",
    "            data = response.json()['data']\n",
    "            dates = data['dataProducts'][0]['availableMonths']\n",
    "            if daterange == 'most recent':\n",
    "                # get the most recent date\n",
    "                dates = [max(dates)]\n",
    "            else:\n",
    "                try:\n",
    "                    # get dates in the range\n",
    "                    assert isinstance(daterange,list)\n",
    "                    begin, terminate = min(daterange), max(daterange)\n",
    "                    dates = [d  for d in dates if (d >= begin) and (d <= terminate)]                 \n",
    "                except AssertionError:\n",
    "                    print('daterange must be a list, e.g. [\\'2020-10\\', \\'2019-10\\']')\n",
    "                    return(None)\n",
    "            # determine the existing products for the dates \n",
    "            for date in dates:\n",
    "                url = f'{server}data/{product}/{site}/{date}'\n",
    "                response = requests.get(url)\n",
    "                data = response.json()\n",
    "                fnames = data['data']['files']\n",
    "                file_name = dict()\n",
    "                for f in fnames:\n",
    "                    for coord in coord_count:\n",
    "                        if coord in f['name']:\n",
    "                            file_name[f['name']] = f['url']\n",
    "            # download the files\n",
    "            try:\n",
    "                download_func(files_dict, savedir, username)\n",
    "            except Exception as e:\n",
    "                print(f'This happened:\\n\\n{e}')\n",
    "        print(f'Done downloading files to {savedir}')     \n",
    "                \n",
    "                \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done downloading files to data\n"
     ]
    }
   ],
   "source": [
    "get_from_API(coord_count, ['BART'], daterange=['2019-08', '2019-08'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aop_sites_split_geojsons.ipynb  downloads.stdout.log  \u001b[0m\u001b[01;34mneon_sites\u001b[0m/\n",
      "\u001b[01;34mdata\u001b[0m/                           \u001b[01;34mgeemap\u001b[0m/               \u001b[01;34mNEON_workshop\u001b[0m/\n",
      "downloads.stderr.log            max_base_plots.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['314000_4879000',\n",
       " '314000_4880000',\n",
       " '314000_4881000',\n",
       " '315000_4879000',\n",
       " '315000_4880000',\n",
       " '316000_4879000',\n",
       " '316000_4880000',\n",
       " '316000_4881000',\n",
       " '316000_4882000',\n",
       " '317000_4878000',\n",
       " '317000_4879000',\n",
       " '317000_4880000',\n",
       " '317000_4881000',\n",
       " '318000_4879000',\n",
       " '318000_4880000',\n",
       " '318000_4881000']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
